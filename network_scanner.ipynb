{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import geopandas as gpd \n",
    "import osmnx as ox\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import time\n",
    "import seaborn as sns\n",
    "import ast\n",
    "import requests\n",
    "from time import sleep\n",
    "import openrouteservice\n",
    "from openrouteservice import client\n",
    "from openrouteservice import convert\n",
    "from shapely.geometry import shape, Point\n",
    "from descartes import PolygonPatch\n",
    "import network_scan_helper as ns\n",
    "import importlib\n",
    "importlib.reload(ns)\n",
    "import contextily as cx\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from datetime import datetime\n",
    "\n",
    "import logging\n",
    "# Clear any existing handlers to avoid duplicate logs\n",
    "for handler in logging.root.handlers[:]:\n",
    "    logging.root.removeHandler(handler)\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.DEBUG,  # Log everything from DEBUG and above\n",
    "    format='%(asctime)s | %(levelname)s | %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    handlers=[\n",
    "        logging.FileHandler(\"log.txt\"),  # Save to file\n",
    "        logging.StreamHandler()          # Show in notebook\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# import administrative boundaries\n",
    "\n",
    "administrative boundary was downloaded from: \n",
    "https://data.humdata.org/dataset/cod-ab-phl\n",
    "\n",
    "### üáµüá≠ Administrative Structure of the Philippines\n",
    "\n",
    "| Level | Administrative Division     | Description / International Equivalent                                         | Number (Approx.)                      |\n",
    "|-------|-----------------------------|--------------------------------------------------------------------------------|---------------------------------------|\n",
    "| 1     | **Country**                 | Sovereign state                                                                | 1                                     |\n",
    "| 2     | **Region**                  | Grouping of provinces for administration and planning (limited autonomy)       | 17 (including BARMM)                  |\n",
    "| 3     | **Province**                | Major political-administrative division; like a state or county               | 82                                    |\n",
    "| 4     | **City / Municipality**     | Subdivisions of provinces; cities are more autonomous than municipalities      | ~1,634 (149 cities, 1,485 municipalities) |\n",
    "| 5     | **Barangay**                | Smallest official unit; like a village, neighborhood, or ward                  | ~42,000+                              |\n",
    "\n",
    "#### üîç Notes:\n",
    "- **Unit of analysis** we are using adm level 4: City/Municipality as a unit of analysis, i.e., City of Manila, Quezon City, San Miguel, Mangatarem, etc. However, in the file downloaded it is labeled ADM3.\n",
    "- **Regions** are primarily administrative and don‚Äôt have elected governments, *except* for **BARMM** (Bangsamoro Autonomous Region in Muslim Mindanao), which is autonomous.\n",
    "- **Cities** can be:\n",
    "  - Highly Urbanized Cities (independent of provinces)\n",
    "  - Component Cities (within provinces)\n",
    "  - Independent Component Cities (not under provincial control)\n",
    "- **Barangays** are crucial for community-level governance and data collection.\n",
    "\n",
    "\n",
    "- focus on road infrastructure investment\n",
    "- redefining city definition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import basic administrative data for the whole country\n",
    "gdf = gpd.read_file('0_raw_data/administrative boundary/phl_admbnda_adm3_psa_namria_20231106.shp')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run analysis for list of cities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(ns)\n",
    "\n",
    "# define city\n",
    "city_list = list(gdf[gdf.ADM1_EN=='National Capital Region (NCR)']['ADM3_EN']) # trying all cities within National Capital Region \n",
    "proj_crs = 3121\n",
    "\n",
    "\n",
    "summary_stats = []\n",
    "for city in city_list:    \n",
    "    try:\n",
    "        # Suppress DeprecationWarnings within this block\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter(\"ignore\")\n",
    "            # START\n",
    "            start = time.time()\n",
    "            # --------------------------------------------\n",
    "            # 1. making AOI\n",
    "            logging.info(f'\\n\\n ------computing for {city}------')\n",
    "            logging.info(f'1. making AOI for {city}')\n",
    "            gdf_city, gdf_city_buffer = ns.get_AOI(gdf=gdf, city=city, proj_crs=proj_crs)\n",
    "            logging.info(f\"done in {time.time() - start:.2f} seconds\")\n",
    "            \n",
    "            # 2. extracting graph, edges, nodes\n",
    "            logging.info(f'2. extracting graph, edges, nodes for {city}')\n",
    "            road_graph, road_edges, road_nodes = ns.extract_road_network(gdf_polygon=gdf_city_buffer, network_type='all', simplify=True, verbose=False)\n",
    "            # export to geojson\n",
    "            road_edges_export = ns.sanitize_gdf_for_export(road_edges)\n",
    "            road_edges_export.to_file(f'output/{city}/geojson/road_edges.geojson')\n",
    "            road_nodes_export = ns.sanitize_gdf_for_export(road_nodes)\n",
    "            road_nodes_export.to_file(f'output/{city}/geojson/road_nodes.geojson')\n",
    "            logging.info(f\"done in {time.time() - start:.2f} seconds\")\n",
    "            \n",
    "            # 3. making basemap\n",
    "            logging.info(f'3. generating basemap AOI for {city}')\n",
    "            fig,ax = ns.map_basemap(gdf_city=gdf_city, gdf_city_buffer=gdf_city_buffer, road_edges=road_edges, road_nodes=road_nodes,crs=proj_crs)\n",
    "            fig.savefig(f'output/{city}/png/map_AOI.png', dpi=300, bbox_inches = 'tight')\n",
    "            logging.info(f\"done in {time.time() - start:.2f} seconds\")\n",
    "\n",
    "            # 4. plotting road hierarchy\n",
    "            logging.info(f'4. plotting road hierarchy for {city}')\n",
    "            fig, ax = ns.map_road_hierarchy(road_edges=road_edges.clip(gdf_city), gdf_border=gdf_city, crs=3121, colormap='plasma')\n",
    "            fig.savefig(f'output/{city}/png/map_road_hierarchy.png', dpi=300, bbox_inches = 'tight')\n",
    "            logging.info(f\"done in {time.time() - start:.2f} seconds\")\n",
    "\n",
    "            # 5. road hierarchy analysis\n",
    "            # calculate length\n",
    "            logging.info(f'5. analyzing road hierarchy for {city}')\n",
    "            desc = road_edges.groupby('highway_cat')['length'].describe()\n",
    "            desc['sum'] = road_edges.groupby('highway_cat')['length'].sum()\n",
    "            desc['length_km'] = desc['sum']/1000\n",
    "            desc.to_csv(f'output/{city}/tabular/road_by_hierarchy.csv')\n",
    "            fig, ax = ns.plot_total_length_by_cat(desc=desc)\n",
    "            fig.savefig(f'output/{city}/png/chart_totalroadlength_by_category.png', dpi=300, bbox_inches='tight')\n",
    "            fig, ax = ns.plot_median_length_by_cat(desc=desc)\n",
    "            fig.savefig(f'output/{city}/png/chart_medianroadlength_by_category.png', dpi=300, bbox_inches='tight')\n",
    "            logging.info(f\"done in {time.time() - start:.2f} seconds\")\n",
    "\n",
    "            # 6. road orientations\n",
    "            logging.info(f'6. mapping road orientation for {city}')\n",
    "            road_bearing = ox.add_edge_bearings(ox.convert.to_undirected(road_graph))\n",
    "            fig, ax = ox.plot.plot_orientation(road_bearing, title=city, area=True, figsize=(8,8))\n",
    "            plt.close()\n",
    "            fig.savefig(f'output/{city}/png/chart_road_orientation.png', dpi=300, bbox_inches='tight')\n",
    "            logging.info(f\"done in {time.time() - start:.2f} seconds\")\n",
    "\n",
    "            # 7. calculate basic stats\n",
    "            logging.info(f'7. calculating basic stats for {city}')\n",
    "            df_stats = ns.calc_basic_stats(graph=road_graph)\n",
    "            df_stats.to_csv(f'output/{city}/tabular/basic_stats.csv')\n",
    "            stats_dict = df_stats[['Metric', 'Value']].set_index('Metric')['Value'].to_dict()\n",
    "            logging.info(f\"done in {time.time() - start:.2f} seconds\")\n",
    "\n",
    "            # 8. calculate lanes and maxspeed\n",
    "            logging.info(f'8. calculating median lanes and maxspeed for {city}')\n",
    "            lanes_speed_df, lanes_sort, speed_sort = ns.compute_lanes_maxspeed(road_edges=road_edges)\n",
    "            lanes_speed_df.to_csv(f'output/{city}/tabular/lanes_speed_by_hierarchy.csv')\n",
    "            fig, ax = ns.plot_median_lanes(lanes_sort=lanes_sort)\n",
    "            fig.savefig(f'output/{city}/png/lanes_by_hierarchy.png', dpi=300, bbox_inches = 'tight')\n",
    "            fig, ax = ns.plot_median_speed(speed_sort=speed_sort)\n",
    "            fig.savefig(f'output/{city}/png/speed_by_hierarchy.png', dpi=300, bbox_inches = 'tight')\n",
    "            logging.info(f\"done in {time.time() - start:.2f} seconds\")\n",
    "            \n",
    "            # 9. calculate and visualize intersection/node degree\n",
    "            logging.info(f'9. calculate and visualize intersection/node degree for {city}')\n",
    "            street_node_df = ns.calculate_intersection(df_stats=df_stats)\n",
    "            street_node_df.to_csv(f'output/{city}/tabular/intersection_by_degree_counts.csv')\n",
    "            fig,ax = ns.map_road_intersections(road_edges=road_edges.clip(gdf_city), road_nodes=road_nodes.clip(gdf_city), gdf_border=gdf_city, crs=3121, colormap='magma_r')\n",
    "            fig.savefig(f'output/{city}/png/map_road_intersections.png', dpi=300, bbox_inches = 'tight')\n",
    "            logging.info(f\"done in {time.time() - start:.2f} seconds\")\n",
    "\n",
    "            # 10. computing and mapping centrality analysis\n",
    "            logging.info(f'10. centrality analysis for {city}')\n",
    "            # determining sample size 5% of nodes, bounded between 100‚Äì1000\n",
    "            n_nodes = len(road_nodes)\n",
    "            k = min(1000, max(100, int(n_nodes * 0.05)))\n",
    "            logging.info(f'total nodes: {n_nodes}, sample size (k): {k}')\n",
    "            # compute centrality\n",
    "            nodes_centrality, edges_centrality =ns.compute_graph_centralities(graph=road_graph, \n",
    "                                                                            degree_centrality=True, \n",
    "                                                                            node_closeness_centrality=True, \n",
    "                                                                            node_betweenness_centrality=True,\n",
    "                                                                            edge_betweenness_centrality=True,\n",
    "                                                                            k=k, #scale according to city size, alternatively use 500 to save computing time\n",
    "                                                                            seed=16\n",
    "                                                                            )\n",
    "            # map closeness centrality\n",
    "            fig, ax = ns.map_nodes_centrality(road_edges=edges_centrality.clip(gdf_city), road_nodes=nodes_centrality.clip(gdf_city), gdf_border=gdf_city, crs=3121, colormap='RdYlGn', column='closeness_centrality')\n",
    "            fig.savefig(f'output/{city}/png/map_closeness_centrality.png', dpi=300, bbox_inches='tight' ) # figure out ways for different weighting, i.e., decay values?\n",
    "            # map betweenness centrality\n",
    "            fig, ax = ns.map_nodes_centrality(road_edges=edges_centrality.clip(gdf_city), road_nodes=nodes_centrality.clip(gdf_city), gdf_border=gdf_city, crs=3121, colormap='magma', column='betweenness_centrality')\n",
    "            fig.savefig(f'output/{city}/png/map_nodes_betweenness_centrality.png', dpi=300, bbox_inches='tight' )\n",
    "            # map edges betweenness centrality\n",
    "            fig, ax = ns.map_edges_centrality(road_edges=edges_centrality.clip(gdf_city), road_nodes=nodes_centrality.clip(gdf_city), gdf_border=gdf_city, crs=3121, colormap='magma')\n",
    "            fig.savefig(f'output/{city}/png/map_edges_betweenness_centrality.png', dpi=300, bbox_inches='tight' )\n",
    "            # map degree centrality\n",
    "            fig, ax = ns.map_nodes_centrality(road_edges=edges_centrality.clip(gdf_city), road_nodes=nodes_centrality.clip(gdf_city), gdf_border=gdf_city, crs=3121, colormap='RdYlBu_r', column='degree_centrality')\n",
    "            fig.savefig(f'output/{city}/png/map_degree_centrality.png', dpi=300, bbox_inches='tight' )\n",
    "            # export to geojson\n",
    "            nodes_centrality_export = ns.sanitize_gdf_for_export(nodes_centrality)\n",
    "            nodes_centrality_export.to_file(f'output/{city}/geojson/nodes_centrality.geojson')\n",
    "            edges_centrality_export = ns.sanitize_gdf_for_export(edges_centrality)\n",
    "            edges_centrality_export.to_file(f'output/{city}/geojson/edges_centrality.geojson')\n",
    "            logging.info(f\"done in {time.time() - start:.2f} seconds\")\n",
    "\n",
    "            # 11. accessibility analysis\n",
    "            logging.info(f'11. accessibility analysis for {city}')\n",
    "            # education facilities\n",
    "            ns.analyze_accessibility(\n",
    "                category='education',\n",
    "                tags={'amenity': ['school', 'kindergarten', 'college', 'university', 'library']},\n",
    "                road_graph=road_graph,\n",
    "                gdf_city_buffer=gdf_city_buffer,\n",
    "                gdf_city=gdf_city,\n",
    "                city=city, \n",
    "                interpolation=False\n",
    "            )\n",
    "            \n",
    "            # healthcare facilities\n",
    "            ns.analyze_accessibility(\n",
    "                category='healthcare',\n",
    "                tags={'amenity': ['clinic', 'hospital']},\n",
    "                road_graph=road_graph,\n",
    "                gdf_city_buffer=gdf_city_buffer,\n",
    "                gdf_city=gdf_city,\n",
    "                city=city, \n",
    "                interpolation=False\n",
    "            )\n",
    "            \n",
    "            # transport facilities\n",
    "            ns.analyze_accessibility(\n",
    "                category='transport',\n",
    "                tags = {\n",
    "                    'amenity': ['bus_station'],\n",
    "                    'public_transport': ['station', 'platform'],\n",
    "                    'railway': ['station'],\n",
    "                },\n",
    "                road_graph=road_graph,\n",
    "                gdf_city_buffer=gdf_city_buffer,\n",
    "                gdf_city=gdf_city,\n",
    "                city=city, \n",
    "                interpolation=False\n",
    "            )\n",
    "            \n",
    "            # green open space facilities\n",
    "            ns.analyze_accessibility(\n",
    "                category='green',\n",
    "                tags = {\n",
    "                    'leisure': ['park', 'garden', 'playground', 'pitch'],\n",
    "                    'landuse': ['recreation_ground', 'grass'],\n",
    "                    'natural': ['wood', 'scrub'],\n",
    "                    'place': ['square']\n",
    "                },\n",
    "                road_graph=road_graph,\n",
    "                gdf_city_buffer=gdf_city_buffer,\n",
    "                gdf_city=gdf_city,\n",
    "                city=city, \n",
    "                interpolation=True\n",
    "            )\n",
    "            \n",
    "            # fire station facilities\n",
    "            ns.analyze_accessibility(\n",
    "                category='fire',\n",
    "                tags = {\n",
    "                    'amenity': ['fire_station'],\n",
    "                },\n",
    "                road_graph=road_graph,\n",
    "                gdf_city_buffer=gdf_city_buffer,\n",
    "                gdf_city=gdf_city,\n",
    "                city=city, \n",
    "                interpolation=False\n",
    "            )\n",
    "            \n",
    "            # food supplies facilities\n",
    "            ns.analyze_accessibility(\n",
    "                category='food',\n",
    "                tags = {\n",
    "                    'shop': ['supermarket', 'convenience', 'marketplace'], \n",
    "                    'amenity': 'marketplace',\n",
    "                },\n",
    "                road_graph=road_graph,\n",
    "                gdf_city_buffer=gdf_city_buffer,\n",
    "                gdf_city=gdf_city,\n",
    "                city=city, \n",
    "                interpolation=False\n",
    "            )\n",
    "\n",
    "\n",
    "            # --------------------------------------------\n",
    "            # END\n",
    "            end = time.time()\n",
    "            total_seconds = int(end - start)\n",
    "            minutes, seconds = divmod(total_seconds, 60)\n",
    "            duration_str = f'{minutes} min {seconds} sec'\n",
    "\n",
    "            # --- store combined results ---\n",
    "            stats_dict['City'] = city\n",
    "            stats_dict['Province'] = gdf_city.ADM3_EN.values[0]\n",
    "            stats_dict['Region'] = gdf_city.ADM2_EN.values[0]\n",
    "            \n",
    "            stats_dict['AREA_SQKM'] = gdf_city.AREA_SQKM.values[0]\n",
    "            stats_dict['duration'] = duration_str\n",
    "            summary_stats.append(stats_dict)\n",
    "    \n",
    "    except Exception as e: \n",
    "        logging.info(f\"‚ö†Ô∏è Skipping {city['name']} due to error: {e}\")\n",
    "        continue\n",
    "\n",
    "# Convert list of dicts to a DataFrame\n",
    "summary_df = pd.DataFrame(summary_stats)\n",
    "\n",
    "# Move 'city' and 'duration' to front\n",
    "cols = ['City', 'Province', 'Region'] + [col for col in summary_df.columns if col not in ['City', 'Region', 'Province', 'duration']] + ['duration']\n",
    "summary_df = summary_df[cols]\n",
    "# Create timestamp string\n",
    "timestamp = datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "summary_df.to_csv(f'output/{timestamp}_summary_statistics.csv')\n",
    "display(summary_df)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bagidata",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
